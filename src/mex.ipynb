{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plmodel import make_optimizer, make_lr_scheduler, SportacusModule\n",
    "from pltrain import init_model, init_datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sportacus = init_model(freeze_body=False)\n",
    "# params = torch.load(\"/workspaces/cv/src/models_checkpoint/epoch=50-step=32436.ckpt\")\n",
    "# sportacus.load_state_dict(params['state_dict']) \n",
    "train_dataset, val_dataset, test_dataset = init_datasets()\n",
    "# model = SportacusModule(\n",
    "#     sportacus,\n",
    "#     make_optimizer,\n",
    "#     train_dataset,\n",
    "#     val_dataset,\n",
    "#     test_dataset,\n",
    "#     make_lr_scheduler,\n",
    "#     64,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SportacusModule.load_from_checkpoint(\n",
    "    '/workspaces/cv/src/models_checkpoint/ep54_head_efn.ckpt',\n",
    "    model=sportacus,\n",
    "    optimizer_fn=make_optimizer,\n",
    "    trainset=train_dataset,\n",
    "    valset=val_dataset,\n",
    "    testset=test_dataset,\n",
    "    lr_scheduler_fn=make_lr_scheduler,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features', 'avgpool', 'classifier']\n"
     ]
    }
   ],
   "source": [
    "print([n for n, _ in model._model.named_children()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [p for p, _ in model._model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.vision_transformer import (\n",
    "    vit_b_16,\n",
    "    ViT_B_16_Weights,\n",
    ")\n",
    "\n",
    "sportacus = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class_token',\n",
       " 'conv_proj.weight',\n",
       " 'conv_proj.bias',\n",
       " 'encoder.pos_embedding',\n",
       " 'encoder.layers.encoder_layer_0.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_0.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_0.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_0.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_0.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_0.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_0.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_0.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_0.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_0.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_0.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_0.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_1.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_1.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_1.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_1.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_1.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_1.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_1.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_1.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_1.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_1.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_1.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_1.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_2.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_2.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_2.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_2.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_2.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_2.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_2.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_2.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_2.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_2.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_2.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_2.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_3.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_3.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_3.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_3.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_3.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_3.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_3.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_3.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_3.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_3.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_3.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_3.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_4.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_4.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_4.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_4.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_4.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_4.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_4.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_4.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_4.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_4.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_4.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_4.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_5.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_5.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_5.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_5.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_5.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_5.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_5.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_5.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_5.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_5.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_5.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_5.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_6.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_6.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_6.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_6.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_6.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_6.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_6.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_6.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_6.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_6.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_6.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_6.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_7.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_7.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_7.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_7.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_7.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_7.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_7.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_7.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_7.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_7.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_7.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_7.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_8.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_8.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_8.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_8.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_8.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_8.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_8.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_8.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_8.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_8.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_8.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_8.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_9.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_9.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_9.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_9.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_9.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_9.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_9.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_9.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_9.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_9.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_9.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_9.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_10.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_10.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_10.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_10.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_10.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_10.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_10.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_10.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_10.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_10.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_10.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_10.mlp.3.bias',\n",
       " 'encoder.layers.encoder_layer_11.ln_1.weight',\n",
       " 'encoder.layers.encoder_layer_11.ln_1.bias',\n",
       " 'encoder.layers.encoder_layer_11.self_attention.in_proj_weight',\n",
       " 'encoder.layers.encoder_layer_11.self_attention.in_proj_bias',\n",
       " 'encoder.layers.encoder_layer_11.self_attention.out_proj.weight',\n",
       " 'encoder.layers.encoder_layer_11.self_attention.out_proj.bias',\n",
       " 'encoder.layers.encoder_layer_11.ln_2.weight',\n",
       " 'encoder.layers.encoder_layer_11.ln_2.bias',\n",
       " 'encoder.layers.encoder_layer_11.mlp.0.weight',\n",
       " 'encoder.layers.encoder_layer_11.mlp.0.bias',\n",
       " 'encoder.layers.encoder_layer_11.mlp.3.weight',\n",
       " 'encoder.layers.encoder_layer_11.mlp.3.bias',\n",
       " 'encoder.ln.weight',\n",
       " 'encoder.ln.bias',\n",
       " 'heads.head.weight',\n",
       " 'heads.head.bias']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p, _ in sportacus.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "last_m = 0\n",
    "for m in arr:\n",
    "    if \"features.7\" in m or \"features.8\" in m or \"classifier\" in m:\n",
    "        last_m += 1\n",
    "\n",
    "print(last_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_model.features.7.0.block.0.0.weight\n",
      "_model.features.7.0.block.0.1.weight\n",
      "_model.features.7.0.block.0.1.bias\n",
      "_model.features.7.0.block.1.0.weight\n",
      "_model.features.7.0.block.1.1.weight\n",
      "_model.features.7.0.block.1.1.bias\n",
      "_model.features.7.0.block.2.fc1.weight\n",
      "_model.features.7.0.block.2.fc1.bias\n",
      "_model.features.7.0.block.2.fc2.weight\n",
      "_model.features.7.0.block.2.fc2.bias\n",
      "_model.features.7.0.block.3.0.weight\n",
      "_model.features.7.0.block.3.1.weight\n",
      "_model.features.7.0.block.3.1.bias\n",
      "_model.features.7.1.block.0.0.weight\n",
      "_model.features.7.1.block.0.1.weight\n",
      "_model.features.7.1.block.0.1.bias\n",
      "_model.features.7.1.block.1.0.weight\n",
      "_model.features.7.1.block.1.1.weight\n",
      "_model.features.7.1.block.1.1.bias\n",
      "_model.features.7.1.block.2.fc1.weight\n",
      "_model.features.7.1.block.2.fc1.bias\n",
      "_model.features.7.1.block.2.fc2.weight\n",
      "_model.features.7.1.block.2.fc2.bias\n",
      "_model.features.7.1.block.3.0.weight\n",
      "_model.features.7.1.block.3.1.weight\n",
      "_model.features.7.1.block.3.1.bias\n",
      "_model.features.7.2.block.0.0.weight\n",
      "_model.features.7.2.block.0.1.weight\n",
      "_model.features.7.2.block.0.1.bias\n",
      "_model.features.7.2.block.1.0.weight\n",
      "_model.features.7.2.block.1.1.weight\n",
      "_model.features.7.2.block.1.1.bias\n",
      "_model.features.7.2.block.2.fc1.weight\n",
      "_model.features.7.2.block.2.fc1.bias\n",
      "_model.features.7.2.block.2.fc2.weight\n",
      "_model.features.7.2.block.2.fc2.bias\n",
      "_model.features.7.2.block.3.0.weight\n",
      "_model.features.7.2.block.3.1.weight\n",
      "_model.features.7.2.block.3.1.bias\n",
      "_model.features.7.3.block.0.0.weight\n",
      "_model.features.7.3.block.0.1.weight\n",
      "_model.features.7.3.block.0.1.bias\n",
      "_model.features.7.3.block.1.0.weight\n",
      "_model.features.7.3.block.1.1.weight\n",
      "_model.features.7.3.block.1.1.bias\n",
      "_model.features.7.3.block.2.fc1.weight\n",
      "_model.features.7.3.block.2.fc1.bias\n",
      "_model.features.7.3.block.2.fc2.weight\n",
      "_model.features.7.3.block.2.fc2.bias\n",
      "_model.features.7.3.block.3.0.weight\n",
      "_model.features.7.3.block.3.1.weight\n",
      "_model.features.7.3.block.3.1.bias\n",
      "_model.features.7.4.block.0.0.weight\n",
      "_model.features.7.4.block.0.1.weight\n",
      "_model.features.7.4.block.0.1.bias\n",
      "_model.features.7.4.block.1.0.weight\n",
      "_model.features.7.4.block.1.1.weight\n",
      "_model.features.7.4.block.1.1.bias\n",
      "_model.features.7.4.block.2.fc1.weight\n",
      "_model.features.7.4.block.2.fc1.bias\n",
      "_model.features.7.4.block.2.fc2.weight\n",
      "_model.features.7.4.block.2.fc2.bias\n",
      "_model.features.7.4.block.3.0.weight\n",
      "_model.features.7.4.block.3.1.weight\n",
      "_model.features.7.4.block.3.1.bias\n",
      "_model.features.8.0.weight\n",
      "_model.features.8.1.weight\n",
      "_model.features.8.1.bias\n",
      "_model.classifier.head.0.1.weight\n",
      "_model.classifier.head.0.1.bias\n",
      "_model.classifier.head.0.2.weight\n",
      "_model.classifier.head.0.2.bias\n",
      "_model.classifier.head.2.1.weight\n",
      "_model.classifier.head.2.1.bias\n",
      "_model.classifier.head.2.2.weight\n",
      "_model.classifier.head.2.2.bias\n",
      "_model.classifier.head.4.1.weight\n",
      "_model.classifier.head.4.1.bias\n",
      "_model.classifier.head.4.2.weight\n",
      "_model.classifier.head.4.2.bias\n",
      "_model.classifier.head.6.1.weight\n",
      "_model.classifier.head.6.1.bias\n"
     ]
    }
   ],
   "source": [
    "for name, par in model.named_parameters():\n",
    "    if (\"features.7\") in name or (\"features.8\") in name or (\"classifier\") in name:\n",
    "        par.requires_grad = True\n",
    "    else:\n",
    "        par.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
